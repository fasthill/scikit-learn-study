{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 이수안 컴퓨터: http://suanlab.com/youtube/ml.html <br>\n",
    "참조; https://needjarvis.tistory.com/621"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGeRH4wq9f5V"
   },
   "source": [
    "# 나이브 베이즈 분류기(Naive Bayes Classification)\n",
    "\n",
    "* 베이즈 정리를 적용한 확률적 분류 알고리즘\n",
    "* 모든 특성들이 독립임을 가정 (naive 가정)\n",
    "* 입력 특성에 따라 3개의 분류기 존재\n",
    "  * 가우시안 나이브 베이즈 분류기\n",
    "  * 베르누이 나이브 베이즈 분류기\n",
    "  * 다항 나이브 베이즈 분류기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dJEOfUP7D0W5"
   },
   "source": [
    "## 나이브 베이즈 분류기의 확률 모델\n",
    "\n",
    "* 나이브 베이즈는 조건부 확률 모델\n",
    "* *N*개의 특성을 나타내는 벡터 **x**를 입력 받아 k개의 가능한 확률적 결과를 출력\n",
    "\n",
    "\\begin{equation}\n",
    "p(C_k | x_1,...,x_n)\n",
    "\\end{equation}\n",
    "\n",
    "* 위의 식에 베이즈 정리를 적용하면 다음과 같음\n",
    "\n",
    "\\begin{equation}\n",
    "p(C_k | \\textbf{x}) = \\frac{p(C_k)p(\\textbf{x}|C_k)}{p(\\textbf{x})}\n",
    "\\end{equation}\n",
    "\n",
    "* 위의 식에서 분자만이 출력 값에 영향을 받기 때문에 분모 부분을 상수로 취급할 수 있음\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(C_k | \\textbf{x}) & \\propto p(C_k)p(\\textbf{x}|C_k) \\\\\n",
    "& \\propto p(C_k, x_1, ..., x_n)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "* 위의 식을 연쇄 법칙을 사용해 다음과 같이 쓸 수 있음\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(C_k, x_1, ..., x_n) & = p(C_k)p(x_1, ..., x_n | C_k) \\\\\n",
    "& = p(C_k)p(x_1 | C_k)p(x_2, ..., x_n | C_k, x_1) \\\\\n",
    "& = p(C_k)p(x_1 | C_k)p(x_2 | C_k, x_1)p(x_3, ..., x_n | C_k, x_1, x_2) \\\\\n",
    "& = p(C_k)p(x_1 | C_k)p(x_2 | C_k, x_1)...p(x_n | C_k, x_1, x_2, ..., x_{n-1})\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "* 나이브 베이즈 분류기는 모든 특성이 독립이라고 가정하기 때문에 위의 식을 다음과 같이 쓸 수 있음\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "p(C_k, x_1, ..., x_n) & \\propto p(C_k)p(x_1|C_k)p(x_2|C_k)...p(x_n|C_k) \\\\\n",
    "& \\propto p(C_k) \\prod_{i=1}^{n} p(x_i|C_k)\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "* 위의 식을 통해 나온 값들 중 가장 큰 값을 갖는 클래스가 예측 결과\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{y} = \\underset{k}{\\arg\\max} \\; p(C_k) \\prod_{i=1}^{n} p(x_i|C_k)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "YWMJk5Q6QRjt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "from sklearn.datasets import fetch_covtype, fetch_20newsgroups, load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2022\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "niugbwwe9dFN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1번째 클래스의 가능성: 0.0162\n",
      "2번째 클래스의 가능성: 0.0042\n",
      "3번째 클래스의 가능성: 0.0039375\n",
      "4번째 클래스의 가능성: 0.0024000000000000002\n"
     ]
    }
   ],
   "source": [
    "prior = [0.45, 0.3, 0.15, 0.1]\n",
    "likelihood = [[0.3, 0.3, 0.4], \n",
    "              [0.7, 0.2, 0.1], \n",
    "              [0.15, 0.5, 0.35],\n",
    "              [0.6, 0.2, 0.2]]\n",
    "idx = 0\n",
    "for c, xs in zip(prior, likelihood):\n",
    "    result = 1.\n",
    "    \n",
    "    for x in xs:\n",
    "        result *= x\n",
    "        \n",
    "    result *= c\n",
    "    \n",
    "    idx += 1\n",
    "    \n",
    "    print(f'{idx}번째 클래스의 가능성: {result}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7NBQpMOmtQz"
   },
   "source": [
    "## 산림 토양 데이터\n",
    "* 산림 지역 토양의 특징 데이터\n",
    "* 토양이 어떤 종류에 속하는지 예측\n",
    "* https://archive.ics.uci.edu/ml/datasets/Covertype 에서 데이터의 자세한 설명 확인 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "id": "COcEy-q-m8CG"
   },
   "outputs": [
    {
     "ename": "error",
     "evalue": "Error -3 while decompressing data: invalid block type",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\datasets\\_covtype.py:163\u001b[0m, in \u001b[0;36mfetch_covtype\u001b[1;34m(data_home, download_if_missing, random_state, shuffle, return_X_y, as_frame)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 163\u001b[0m     X, y\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: local variable 'X' referenced before assignment",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [26]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m covtype \u001b[38;5;241m=\u001b[39m fetch_covtype() \u001b[38;5;66;03m# covtype => cover type. forest cover type\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(covtype\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(covtype\u001b[38;5;241m.\u001b[39mDESCR())\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[0;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[0;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[0;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\datasets\\_covtype.py:165\u001b[0m, in \u001b[0;36mfetch_covtype\u001b[1;34m(data_home, download_if_missing, random_state, shuffle, return_X_y, as_frame)\u001b[0m\n\u001b[0;32m    163\u001b[0m     X, y\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNameError\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msamples_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     y \u001b[38;5;241m=\u001b[39m joblib\u001b[38;5;241m.\u001b[39mload(targets_path)\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle:\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py:585\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    579\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    580\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    581\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    582\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[0;32m    583\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[1;32m--> 585\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py:504\u001b[0m, in \u001b[0;36m_unpickle\u001b[1;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[0;32m    502\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 504\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[0;32m    506\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    507\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    508\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    509\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[0;32m    510\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[0;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[1;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[0;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py:342\u001b[0m, in \u001b[0;36mNumpyUnpickler.load_build\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array_wrapper, NDArrayWrapper):\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompat_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 342\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstack\u001b[38;5;241m.\u001b[39mappend(\u001b[43marray_wrapper\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py:187\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    185\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_mmap(unpickler)\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 187\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;66;03m# Manage array subclass case\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(array, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__array_prepare__\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubclass \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (unpickler\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m    192\u001b[0m                           unpickler\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mmemmap)):\n\u001b[0;32m    193\u001b[0m     \u001b[38;5;66;03m# We need to reconstruct another subclass\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle.py:137\u001b[0m, in \u001b[0;36mNumpyArrayWrapper.read_array\u001b[1;34m(self, unpickler)\u001b[0m\n\u001b[0;32m    135\u001b[0m read_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(max_read_count, count \u001b[38;5;241m-\u001b[39m i)\n\u001b[0;32m    136\u001b[0m read_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(read_count \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mitemsize)\n\u001b[1;32m--> 137\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43m_read_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfile_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mread_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43marray data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m array[i:i \u001b[38;5;241m+\u001b[39m read_count] \u001b[38;5;241m=\u001b[39m \\\n\u001b[0;32m    140\u001b[0m     unpickler\u001b[38;5;241m.\u001b[39mnp\u001b[38;5;241m.\u001b[39mfrombuffer(data, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    141\u001b[0m                             count\u001b[38;5;241m=\u001b[39mread_count)\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\numpy_pickle_utils.py:218\u001b[0m, in \u001b[0;36m_read_bytes\u001b[1;34m(fp, size, error_template)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     \u001b[38;5;66;03m# io files (default in python3) return None or raise on\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# would-block, python2 file will truncate, probably nothing can be\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# done about that.  note that regular files can't be non-blocking\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    219\u001b[0m         data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m r\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(r) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m==\u001b[39m size:\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\compressor.py:464\u001b[0m, in \u001b[0;36mBinaryZlibFile.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;124;03m\"\"\"Read up to len(b) bytes into b.\u001b[39;00m\n\u001b[0;32m    460\u001b[0m \n\u001b[0;32m    461\u001b[0m \u001b[38;5;124;03mReturns the number of bytes read (0 for EOF).\u001b[39;00m\n\u001b[0;32m    462\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    463\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBufferedIOBase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadinto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\compressor.py:456\u001b[0m, in \u001b[0;36mBinaryZlibFile.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_all()\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_read_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\compressor.py:429\u001b[0m, in \u001b[0;36mBinaryZlibFile._read_block\u001b[1;34m(self, n_bytes, return_data)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    428\u001b[0m blocks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 429\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m n_bytes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fill_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    430\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_bytes \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer):\n\u001b[0;32m    431\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:n_bytes]\n",
      "File \u001b[1;32mc:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\joblib\\compressor.py:393\u001b[0m, in \u001b[0;36mBinaryZlibFile._fill_buffer\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    392\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 393\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decompressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrawblock\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    394\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31merror\u001b[0m: Error -3 while decompressing data: invalid block type"
     ]
    }
   ],
   "source": [
    "# covtype = fetch_covtype() # covtype => cover type. forest cover type\n",
    "# print(covtype.keys())\n",
    "# print(covtype.DESCR())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 명령이 작동하지 않아서, 아래와 같이 따로 데이터를 받아서 거꾸로 데이터를 구성하여 진행 <br>\n",
    "kaggle에서 자료 download: https://www.kaggle.com/uciml/forest-cover-type-dataset/version/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_df = pd.read_csv(\"./data/covtype.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2596</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>258</td>\n",
       "      <td>0</td>\n",
       "      <td>510</td>\n",
       "      <td>221</td>\n",
       "      <td>232</td>\n",
       "      <td>148</td>\n",
       "      <td>6279</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2590</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "      <td>212</td>\n",
       "      <td>-6</td>\n",
       "      <td>390</td>\n",
       "      <td>220</td>\n",
       "      <td>235</td>\n",
       "      <td>151</td>\n",
       "      <td>6225</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2804</td>\n",
       "      <td>139</td>\n",
       "      <td>9</td>\n",
       "      <td>268</td>\n",
       "      <td>65</td>\n",
       "      <td>3180</td>\n",
       "      <td>234</td>\n",
       "      <td>238</td>\n",
       "      <td>135</td>\n",
       "      <td>6121</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2785</td>\n",
       "      <td>155</td>\n",
       "      <td>18</td>\n",
       "      <td>242</td>\n",
       "      <td>118</td>\n",
       "      <td>3090</td>\n",
       "      <td>238</td>\n",
       "      <td>238</td>\n",
       "      <td>122</td>\n",
       "      <td>6211</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2595</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>153</td>\n",
       "      <td>-1</td>\n",
       "      <td>391</td>\n",
       "      <td>220</td>\n",
       "      <td>234</td>\n",
       "      <td>150</td>\n",
       "      <td>6172</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Elevation  Aspect  Slope  Horizontal_Distance_To_Hydrology  \\\n",
       "0       2596      51      3                               258   \n",
       "1       2590      56      2                               212   \n",
       "2       2804     139      9                               268   \n",
       "3       2785     155     18                               242   \n",
       "4       2595      45      2                               153   \n",
       "\n",
       "   Vertical_Distance_To_Hydrology  Horizontal_Distance_To_Roadways  \\\n",
       "0                               0                              510   \n",
       "1                              -6                              390   \n",
       "2                              65                             3180   \n",
       "3                             118                             3090   \n",
       "4                              -1                              391   \n",
       "\n",
       "   Hillshade_9am  Hillshade_Noon  Hillshade_3pm  \\\n",
       "0            221             232            148   \n",
       "1            220             235            151   \n",
       "2            234             238            135   \n",
       "3            238             238            122   \n",
       "4            220             234            150   \n",
       "\n",
       "   Horizontal_Distance_To_Fire_Points  ...  Soil_Type32  Soil_Type33  \\\n",
       "0                                6279  ...            0            0   \n",
       "1                                6225  ...            0            0   \n",
       "2                                6121  ...            0            0   \n",
       "3                                6211  ...            0            0   \n",
       "4                                6172  ...            0            0   \n",
       "\n",
       "   Soil_Type34  Soil_Type35  Soil_Type36  Soil_Type37  Soil_Type38  \\\n",
       "0            0            0            0            0            0   \n",
       "1            0            0            0            0            0   \n",
       "2            0            0            0            0            0   \n",
       "3            0            0            0            0            0   \n",
       "4            0            0            0            0            0   \n",
       "\n",
       "   Soil_Type39  Soil_Type40  Cover_Type  \n",
       "0            0            0           5  \n",
       "1            0            0           5  \n",
       "2            0            0           2  \n",
       "3            0            0           2  \n",
       "4            0            0           5  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = covtype_df.iloc[:, :-1].values\n",
    "y = covtype_df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(581012, 54)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(np.unique(y))\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "      <th>Cover_Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "      <td>581012.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2959.365301</td>\n",
       "      <td>155.656807</td>\n",
       "      <td>14.103704</td>\n",
       "      <td>269.428217</td>\n",
       "      <td>46.418855</td>\n",
       "      <td>2350.146611</td>\n",
       "      <td>212.146049</td>\n",
       "      <td>223.318716</td>\n",
       "      <td>142.528263</td>\n",
       "      <td>1980.291226</td>\n",
       "      <td>...</td>\n",
       "      <td>0.090392</td>\n",
       "      <td>0.077716</td>\n",
       "      <td>0.002773</td>\n",
       "      <td>0.003255</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.026803</td>\n",
       "      <td>0.023762</td>\n",
       "      <td>0.015060</td>\n",
       "      <td>2.051471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>279.984734</td>\n",
       "      <td>111.913721</td>\n",
       "      <td>7.488242</td>\n",
       "      <td>212.549356</td>\n",
       "      <td>58.295232</td>\n",
       "      <td>1559.254870</td>\n",
       "      <td>26.769889</td>\n",
       "      <td>19.768697</td>\n",
       "      <td>38.274529</td>\n",
       "      <td>1324.195210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.286743</td>\n",
       "      <td>0.267725</td>\n",
       "      <td>0.052584</td>\n",
       "      <td>0.056957</td>\n",
       "      <td>0.014310</td>\n",
       "      <td>0.022641</td>\n",
       "      <td>0.161508</td>\n",
       "      <td>0.152307</td>\n",
       "      <td>0.121791</td>\n",
       "      <td>1.396504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1859.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-173.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2809.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1106.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2996.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1710.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3163.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3328.000000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3858.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>1397.000000</td>\n",
       "      <td>601.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7173.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Elevation         Aspect          Slope  \\\n",
       "count  581012.000000  581012.000000  581012.000000   \n",
       "mean     2959.365301     155.656807      14.103704   \n",
       "std       279.984734     111.913721       7.488242   \n",
       "min      1859.000000       0.000000       0.000000   \n",
       "25%      2809.000000      58.000000       9.000000   \n",
       "50%      2996.000000     127.000000      13.000000   \n",
       "75%      3163.000000     260.000000      18.000000   \n",
       "max      3858.000000     360.000000      66.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                     581012.000000                   581012.000000   \n",
       "mean                         269.428217                       46.418855   \n",
       "std                          212.549356                       58.295232   \n",
       "min                            0.000000                     -173.000000   \n",
       "25%                          108.000000                        7.000000   \n",
       "50%                          218.000000                       30.000000   \n",
       "75%                          384.000000                       69.000000   \n",
       "max                         1397.000000                      601.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                    581012.000000  581012.000000   581012.000000   \n",
       "mean                       2350.146611     212.146049      223.318716   \n",
       "std                        1559.254870      26.769889       19.768697   \n",
       "min                           0.000000       0.000000        0.000000   \n",
       "25%                        1106.000000     198.000000      213.000000   \n",
       "50%                        1997.000000     218.000000      226.000000   \n",
       "75%                        3328.000000     231.000000      237.000000   \n",
       "max                        7117.000000     254.000000      254.000000   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  ...    Soil_Type32  \\\n",
       "count  581012.000000                       581012.000000  ...  581012.000000   \n",
       "mean      142.528263                         1980.291226  ...       0.090392   \n",
       "std        38.274529                         1324.195210  ...       0.286743   \n",
       "min         0.000000                            0.000000  ...       0.000000   \n",
       "25%       119.000000                         1024.000000  ...       0.000000   \n",
       "50%       143.000000                         1710.000000  ...       0.000000   \n",
       "75%       168.000000                         2550.000000  ...       0.000000   \n",
       "max       254.000000                         7173.000000  ...       1.000000   \n",
       "\n",
       "         Soil_Type33    Soil_Type34    Soil_Type35    Soil_Type36  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.077716       0.002773       0.003255       0.000205   \n",
       "std         0.267725       0.052584       0.056957       0.014310   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type37    Soil_Type38    Soil_Type39    Soil_Type40  \\\n",
       "count  581012.000000  581012.000000  581012.000000  581012.000000   \n",
       "mean        0.000513       0.026803       0.023762       0.015060   \n",
       "std         0.022641       0.161508       0.152307       0.121791   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "          Cover_Type  \n",
       "count  581012.000000  \n",
       "mean        2.051471  \n",
       "std         1.396504  \n",
       "min         1.000000  \n",
       "25%         1.000000  \n",
       "50%         2.000000  \n",
       "75%         2.000000  \n",
       "max         7.000000  \n",
       "\n",
       "[8 rows x 55 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 581012 entries, 0 to 581011\n",
      "Data columns (total 55 columns):\n",
      " #   Column                              Non-Null Count   Dtype\n",
      "---  ------                              --------------   -----\n",
      " 0   Elevation                           581012 non-null  int64\n",
      " 1   Aspect                              581012 non-null  int64\n",
      " 2   Slope                               581012 non-null  int64\n",
      " 3   Horizontal_Distance_To_Hydrology    581012 non-null  int64\n",
      " 4   Vertical_Distance_To_Hydrology      581012 non-null  int64\n",
      " 5   Horizontal_Distance_To_Roadways     581012 non-null  int64\n",
      " 6   Hillshade_9am                       581012 non-null  int64\n",
      " 7   Hillshade_Noon                      581012 non-null  int64\n",
      " 8   Hillshade_3pm                       581012 non-null  int64\n",
      " 9   Horizontal_Distance_To_Fire_Points  581012 non-null  int64\n",
      " 10  Wilderness_Area1                    581012 non-null  int64\n",
      " 11  Wilderness_Area2                    581012 non-null  int64\n",
      " 12  Wilderness_Area3                    581012 non-null  int64\n",
      " 13  Wilderness_Area4                    581012 non-null  int64\n",
      " 14  Soil_Type1                          581012 non-null  int64\n",
      " 15  Soil_Type2                          581012 non-null  int64\n",
      " 16  Soil_Type3                          581012 non-null  int64\n",
      " 17  Soil_Type4                          581012 non-null  int64\n",
      " 18  Soil_Type5                          581012 non-null  int64\n",
      " 19  Soil_Type6                          581012 non-null  int64\n",
      " 20  Soil_Type7                          581012 non-null  int64\n",
      " 21  Soil_Type8                          581012 non-null  int64\n",
      " 22  Soil_Type9                          581012 non-null  int64\n",
      " 23  Soil_Type10                         581012 non-null  int64\n",
      " 24  Soil_Type11                         581012 non-null  int64\n",
      " 25  Soil_Type12                         581012 non-null  int64\n",
      " 26  Soil_Type13                         581012 non-null  int64\n",
      " 27  Soil_Type14                         581012 non-null  int64\n",
      " 28  Soil_Type15                         581012 non-null  int64\n",
      " 29  Soil_Type16                         581012 non-null  int64\n",
      " 30  Soil_Type17                         581012 non-null  int64\n",
      " 31  Soil_Type18                         581012 non-null  int64\n",
      " 32  Soil_Type19                         581012 non-null  int64\n",
      " 33  Soil_Type20                         581012 non-null  int64\n",
      " 34  Soil_Type21                         581012 non-null  int64\n",
      " 35  Soil_Type22                         581012 non-null  int64\n",
      " 36  Soil_Type23                         581012 non-null  int64\n",
      " 37  Soil_Type24                         581012 non-null  int64\n",
      " 38  Soil_Type25                         581012 non-null  int64\n",
      " 39  Soil_Type26                         581012 non-null  int64\n",
      " 40  Soil_Type27                         581012 non-null  int64\n",
      " 41  Soil_Type28                         581012 non-null  int64\n",
      " 42  Soil_Type29                         581012 non-null  int64\n",
      " 43  Soil_Type30                         581012 non-null  int64\n",
      " 44  Soil_Type31                         581012 non-null  int64\n",
      " 45  Soil_Type32                         581012 non-null  int64\n",
      " 46  Soil_Type33                         581012 non-null  int64\n",
      " 47  Soil_Type34                         581012 non-null  int64\n",
      " 48  Soil_Type35                         581012 non-null  int64\n",
      " 49  Soil_Type36                         581012 non-null  int64\n",
      " 50  Soil_Type37                         581012 non-null  int64\n",
      " 51  Soil_Type38                         581012 non-null  int64\n",
      " 52  Soil_Type39                         581012 non-null  int64\n",
      " 53  Soil_Type40                         581012 non-null  int64\n",
      " 54  Cover_Type                          581012 non-null  int64\n",
      "dtypes: int64(55)\n",
      "memory usage: 243.8 MB\n"
     ]
    }
   ],
   "source": [
    "covtype_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2596,   51,    3, ...,    0,    0,    0],\n",
       "       [2590,   56,    2, ...,    0,    0,    0],\n",
       "       [2804,  139,    9, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [2386,  159,   17, ...,    0,    0,    0],\n",
       "       [2384,  170,   15, ...,    0,    0,    0],\n",
       "       [2383,  165,   13, ...,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X # == contype.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 5, 2, ..., 3, 3, 3], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # == contype.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W3oFEYsFmzAo"
   },
   "source": [
    "### 학습, 평가 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "covtype_X = X\n",
    "covtype_y = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "LXRNok95nZyL"
   },
   "outputs": [],
   "source": [
    "covtype_X_train, covtype_X_test, covtype_y_train, covtype_y_test = \\\n",
    "     train_test_split(covtype_X, covtype_y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "PcPjkEKKoAG0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 데이터 크기: (581012, 54)\n",
      "학습 데이터 크기: (464809, 54)\n",
      "평가 데이터 크기: (116203, 54)\n"
     ]
    }
   ],
   "source": [
    "print('전체 데이터 크기: {}'.format(covtype_X.shape))\n",
    "print('학습 데이터 크기: {}'.format(covtype_X_train.shape))\n",
    "print('평가 데이터 크기: {}'.format(covtype_X_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lTXhaso1m1RN"
   },
   "source": [
    "### 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABo0ZvzrNlID"
   },
   "source": [
    "#### 전처리 전 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "S8bMSKlHM00-"
   },
   "outputs": [],
   "source": [
    "covtype_train_df = pd.DataFrame(covtype_X_train, columns=covtype_df.columns[:-1])\n",
    "covtype_test_df = pd.DataFrame(covtype_X_test, columns=covtype_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2957.354010</td>\n",
       "      <td>155.793000</td>\n",
       "      <td>14.107983</td>\n",
       "      <td>268.416900</td>\n",
       "      <td>46.169092</td>\n",
       "      <td>2350.421160</td>\n",
       "      <td>212.041711</td>\n",
       "      <td>223.214521</td>\n",
       "      <td>142.544754</td>\n",
       "      <td>1977.881544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043501</td>\n",
       "      <td>0.089602</td>\n",
       "      <td>0.077803</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000465</td>\n",
       "      <td>0.026153</td>\n",
       "      <td>0.023992</td>\n",
       "      <td>0.014862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>280.031606</td>\n",
       "      <td>112.168842</td>\n",
       "      <td>7.511816</td>\n",
       "      <td>211.984495</td>\n",
       "      <td>57.967665</td>\n",
       "      <td>1556.899298</td>\n",
       "      <td>26.832226</td>\n",
       "      <td>19.857622</td>\n",
       "      <td>38.222096</td>\n",
       "      <td>1323.179908</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203984</td>\n",
       "      <td>0.285612</td>\n",
       "      <td>0.267863</td>\n",
       "      <td>0.053215</td>\n",
       "      <td>0.056186</td>\n",
       "      <td>0.013442</td>\n",
       "      <td>0.021552</td>\n",
       "      <td>0.159589</td>\n",
       "      <td>0.153026</td>\n",
       "      <td>0.121001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1866.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-163.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2806.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>108.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1107.000000</td>\n",
       "      <td>198.000000</td>\n",
       "      <td>213.000000</td>\n",
       "      <td>119.000000</td>\n",
       "      <td>1024.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2994.000000</td>\n",
       "      <td>127.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>218.000000</td>\n",
       "      <td>226.000000</td>\n",
       "      <td>143.000000</td>\n",
       "      <td>1708.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3162.000000</td>\n",
       "      <td>261.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>3329.500000</td>\n",
       "      <td>231.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>2544.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3857.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1358.000000</td>\n",
       "      <td>598.000000</td>\n",
       "      <td>7117.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>254.000000</td>\n",
       "      <td>7172.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Elevation         Aspect          Slope  \\\n",
       "count  116203.000000  116203.000000  116203.000000   \n",
       "mean     2957.354010     155.793000      14.107983   \n",
       "std       280.031606     112.168842       7.511816   \n",
       "min      1866.000000       0.000000       0.000000   \n",
       "25%      2806.000000      58.000000       9.000000   \n",
       "50%      2994.000000     127.000000      13.000000   \n",
       "75%      3162.000000     261.000000      18.000000   \n",
       "max      3857.000000     360.000000      61.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                     116203.000000                   116203.000000   \n",
       "mean                         268.416900                       46.169092   \n",
       "std                          211.984495                       57.967665   \n",
       "min                            0.000000                     -163.000000   \n",
       "25%                          108.000000                        7.000000   \n",
       "50%                          218.000000                       29.000000   \n",
       "75%                          384.000000                       69.000000   \n",
       "max                         1358.000000                      598.000000   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                    116203.000000  116203.000000   116203.000000   \n",
       "mean                       2350.421160     212.041711      223.214521   \n",
       "std                        1556.899298      26.832226       19.857622   \n",
       "min                           0.000000       0.000000        0.000000   \n",
       "25%                        1107.000000     198.000000      213.000000   \n",
       "50%                        2001.000000     218.000000      226.000000   \n",
       "75%                        3329.500000     231.000000      237.000000   \n",
       "max                        7117.000000     254.000000      254.000000   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  ...    Soil_Type31  \\\n",
       "count  116203.000000                       116203.000000  ...  116203.000000   \n",
       "mean      142.544754                         1977.881544  ...       0.043501   \n",
       "std        38.222096                         1323.179908  ...       0.203984   \n",
       "min         0.000000                            0.000000  ...       0.000000   \n",
       "25%       119.000000                         1024.000000  ...       0.000000   \n",
       "50%       143.000000                         1708.000000  ...       0.000000   \n",
       "75%       168.000000                         2544.000000  ...       0.000000   \n",
       "max       254.000000                         7172.000000  ...       1.000000   \n",
       "\n",
       "         Soil_Type32    Soil_Type33    Soil_Type34    Soil_Type35  \\\n",
       "count  116203.000000  116203.000000  116203.000000  116203.000000   \n",
       "mean        0.089602       0.077803       0.002840       0.003167   \n",
       "std         0.285612       0.267863       0.053215       0.056186   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type36    Soil_Type37    Soil_Type38    Soil_Type39  \\\n",
       "count  116203.000000  116203.000000  116203.000000  116203.000000   \n",
       "mean        0.000181       0.000465       0.026153       0.023992   \n",
       "std         0.013442       0.021552       0.159589       0.153026   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.000000       0.000000       0.000000       0.000000   \n",
       "50%         0.000000       0.000000       0.000000       0.000000   \n",
       "75%         0.000000       0.000000       0.000000       0.000000   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "         Soil_Type40  \n",
       "count  116203.000000  \n",
       "mean        0.014862  \n",
       "std         0.121001  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_test_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FRsWUNBjN9q9"
   },
   "source": [
    "#### 전처리 과정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "zLYMfVwwpIMH"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "covtype_X_train_scale = scaler.fit_transform(covtype_X_train)\n",
    "covtype_X_test_scale = scaler.transform(covtype_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8l7rTxROCgr"
   },
   "source": [
    "#### 전처리 후 데이터\n",
    "* 평균은 0에 가깝게, 표준평차는 1에 가깝게 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "it55pXLoOGBa"
   },
   "outputs": [],
   "source": [
    "covtype_train_scale_df = pd.DataFrame(covtype_X_train_scale, columns=covtype_df.columns[:-1])\n",
    "covtype_test_scale_df = pd.DataFrame(covtype_X_test_scale, columns=covtype_df.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "yOdlTT1dOcss"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Elevation</th>\n",
       "      <th>Aspect</th>\n",
       "      <th>Slope</th>\n",
       "      <th>Horizontal_Distance_To_Hydrology</th>\n",
       "      <th>Vertical_Distance_To_Hydrology</th>\n",
       "      <th>Horizontal_Distance_To_Roadways</th>\n",
       "      <th>Hillshade_9am</th>\n",
       "      <th>Hillshade_Noon</th>\n",
       "      <th>Hillshade_3pm</th>\n",
       "      <th>Horizontal_Distance_To_Fire_Points</th>\n",
       "      <th>...</th>\n",
       "      <th>Soil_Type31</th>\n",
       "      <th>Soil_Type32</th>\n",
       "      <th>Soil_Type33</th>\n",
       "      <th>Soil_Type34</th>\n",
       "      <th>Soil_Type35</th>\n",
       "      <th>Soil_Type36</th>\n",
       "      <th>Soil_Type37</th>\n",
       "      <th>Soil_Type38</th>\n",
       "      <th>Soil_Type39</th>\n",
       "      <th>Soil_Type40</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "      <td>116203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-0.008980</td>\n",
       "      <td>0.001522</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>-0.005944</td>\n",
       "      <td>-0.005348</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-0.004875</td>\n",
       "      <td>-0.006596</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>-0.002274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004088</td>\n",
       "      <td>-0.003442</td>\n",
       "      <td>0.000408</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>-0.001920</td>\n",
       "      <td>-0.002075</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>-0.005022</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>-0.002029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000217</td>\n",
       "      <td>1.002852</td>\n",
       "      <td>1.003940</td>\n",
       "      <td>0.996685</td>\n",
       "      <td>0.992994</td>\n",
       "      <td>0.998113</td>\n",
       "      <td>1.002916</td>\n",
       "      <td>1.005637</td>\n",
       "      <td>0.998288</td>\n",
       "      <td>0.999042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.990906</td>\n",
       "      <td>0.995076</td>\n",
       "      <td>1.000648</td>\n",
       "      <td>1.015067</td>\n",
       "      <td>0.983169</td>\n",
       "      <td>0.925835</td>\n",
       "      <td>0.940904</td>\n",
       "      <td>0.985218</td>\n",
       "      <td>1.005915</td>\n",
       "      <td>0.991905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.907080</td>\n",
       "      <td>-1.391355</td>\n",
       "      <td>-1.884790</td>\n",
       "      <td>-1.267956</td>\n",
       "      <td>-3.588442</td>\n",
       "      <td>-1.506612</td>\n",
       "      <td>-7.930418</td>\n",
       "      <td>-11.310705</td>\n",
       "      <td>-3.722460</td>\n",
       "      <td>-1.495637</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215408</td>\n",
       "      <td>-0.315617</td>\n",
       "      <td>-0.290240</td>\n",
       "      <td>-0.052570</td>\n",
       "      <td>-0.057336</td>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.166473</td>\n",
       "      <td>-0.155820</td>\n",
       "      <td>-0.123860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.549586</td>\n",
       "      <td>-0.872802</td>\n",
       "      <td>-0.681957</td>\n",
       "      <td>-0.760174</td>\n",
       "      <td>-0.676320</td>\n",
       "      <td>-0.796925</td>\n",
       "      <td>-0.529716</td>\n",
       "      <td>-0.523883</td>\n",
       "      <td>-0.614406</td>\n",
       "      <td>-0.722485</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215408</td>\n",
       "      <td>-0.315617</td>\n",
       "      <td>-0.290240</td>\n",
       "      <td>-0.052570</td>\n",
       "      <td>-0.057336</td>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.166473</td>\n",
       "      <td>-0.155820</td>\n",
       "      <td>-0.123860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.121912</td>\n",
       "      <td>-0.255903</td>\n",
       "      <td>-0.147365</td>\n",
       "      <td>-0.242988</td>\n",
       "      <td>-0.299457</td>\n",
       "      <td>-0.223790</td>\n",
       "      <td>0.217830</td>\n",
       "      <td>0.134467</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>-0.206043</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215408</td>\n",
       "      <td>-0.315617</td>\n",
       "      <td>-0.290240</td>\n",
       "      <td>-0.052570</td>\n",
       "      <td>-0.057336</td>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.166473</td>\n",
       "      <td>-0.155820</td>\n",
       "      <td>-0.123860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.721975</td>\n",
       "      <td>0.942131</td>\n",
       "      <td>0.520876</td>\n",
       "      <td>0.537492</td>\n",
       "      <td>0.385748</td>\n",
       "      <td>0.627898</td>\n",
       "      <td>0.703735</td>\n",
       "      <td>0.691533</td>\n",
       "      <td>0.665381</td>\n",
       "      <td>0.425163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.215408</td>\n",
       "      <td>-0.315617</td>\n",
       "      <td>-0.290240</td>\n",
       "      <td>-0.052570</td>\n",
       "      <td>-0.057336</td>\n",
       "      <td>-0.014522</td>\n",
       "      <td>-0.022918</td>\n",
       "      <td>-0.166473</td>\n",
       "      <td>-0.155820</td>\n",
       "      <td>-0.123860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.204377</td>\n",
       "      <td>1.827247</td>\n",
       "      <td>6.267744</td>\n",
       "      <td>5.116936</td>\n",
       "      <td>9.447588</td>\n",
       "      <td>3.056026</td>\n",
       "      <td>1.563412</td>\n",
       "      <td>1.552453</td>\n",
       "      <td>2.911538</td>\n",
       "      <td>3.919448</td>\n",
       "      <td>...</td>\n",
       "      <td>4.642359</td>\n",
       "      <td>3.168400</td>\n",
       "      <td>3.445426</td>\n",
       "      <td>19.022317</td>\n",
       "      <td>17.441131</td>\n",
       "      <td>68.861811</td>\n",
       "      <td>43.634332</td>\n",
       "      <td>6.006984</td>\n",
       "      <td>6.417658</td>\n",
       "      <td>8.073650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Elevation         Aspect          Slope  \\\n",
       "count  116203.000000  116203.000000  116203.000000   \n",
       "mean       -0.008980       0.001522       0.000715   \n",
       "std         1.000217       1.002852       1.003940   \n",
       "min        -3.907080      -1.391355      -1.884790   \n",
       "25%        -0.549586      -0.872802      -0.681957   \n",
       "50%         0.121912      -0.255903      -0.147365   \n",
       "75%         0.721975       0.942131       0.520876   \n",
       "max         3.204377       1.827247       6.267744   \n",
       "\n",
       "       Horizontal_Distance_To_Hydrology  Vertical_Distance_To_Hydrology  \\\n",
       "count                     116203.000000                   116203.000000   \n",
       "mean                          -0.005944                       -0.005348   \n",
       "std                            0.996685                        0.992994   \n",
       "min                           -1.267956                       -3.588442   \n",
       "25%                           -0.760174                       -0.676320   \n",
       "50%                           -0.242988                       -0.299457   \n",
       "75%                            0.537492                        0.385748   \n",
       "max                            5.116936                        9.447588   \n",
       "\n",
       "       Horizontal_Distance_To_Roadways  Hillshade_9am  Hillshade_Noon  \\\n",
       "count                    116203.000000  116203.000000   116203.000000   \n",
       "mean                          0.000220      -0.004875       -0.006596   \n",
       "std                           0.998113       1.002916        1.005637   \n",
       "min                          -1.506612      -7.930418      -11.310705   \n",
       "25%                          -0.796925      -0.529716       -0.523883   \n",
       "50%                          -0.223790       0.217830        0.134467   \n",
       "75%                           0.627898       0.703735        0.691533   \n",
       "max                           3.056026       1.563412        1.552453   \n",
       "\n",
       "       Hillshade_3pm  Horizontal_Distance_To_Fire_Points  ...    Soil_Type31  \\\n",
       "count  116203.000000                       116203.000000  ...  116203.000000   \n",
       "mean        0.000538                           -0.002274  ...      -0.004088   \n",
       "std         0.998288                            0.999042  ...       0.990906   \n",
       "min        -3.722460                           -1.495637  ...      -0.215408   \n",
       "25%        -0.614406                           -0.722485  ...      -0.215408   \n",
       "50%         0.012429                           -0.206043  ...      -0.215408   \n",
       "75%         0.665381                            0.425163  ...      -0.215408   \n",
       "max         2.911538                            3.919448  ...       4.642359   \n",
       "\n",
       "         Soil_Type32    Soil_Type33    Soil_Type34    Soil_Type35  \\\n",
       "count  116203.000000  116203.000000  116203.000000  116203.000000   \n",
       "mean       -0.003442       0.000408       0.001600      -0.001920   \n",
       "std         0.995076       1.000648       1.015067       0.983169   \n",
       "min        -0.315617      -0.290240      -0.052570      -0.057336   \n",
       "25%        -0.315617      -0.290240      -0.052570      -0.057336   \n",
       "50%        -0.315617      -0.290240      -0.052570      -0.057336   \n",
       "75%        -0.315617      -0.290240      -0.052570      -0.057336   \n",
       "max         3.168400       3.445426      19.022317      17.441131   \n",
       "\n",
       "         Soil_Type36    Soil_Type37    Soil_Type38    Soil_Type39  \\\n",
       "count  116203.000000  116203.000000  116203.000000  116203.000000   \n",
       "mean       -0.002075      -0.002630      -0.005022       0.001894   \n",
       "std         0.925835       0.940904       0.985218       1.005915   \n",
       "min        -0.014522      -0.022918      -0.166473      -0.155820   \n",
       "25%        -0.014522      -0.022918      -0.166473      -0.155820   \n",
       "50%        -0.014522      -0.022918      -0.166473      -0.155820   \n",
       "75%        -0.014522      -0.022918      -0.166473      -0.155820   \n",
       "max        68.861811      43.634332       6.006984       6.417658   \n",
       "\n",
       "         Soil_Type40  \n",
       "count  116203.000000  \n",
       "mean       -0.002029  \n",
       "std         0.991905  \n",
       "min        -0.123860  \n",
       "25%        -0.123860  \n",
       "50%        -0.123860  \n",
       "75%        -0.123860  \n",
       "max         8.073650  \n",
       "\n",
       "[8 rows x 54 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covtype_test_scale_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PA45idG9ayMV"
   },
   "source": [
    "## 20 Newsgroup 데이터\n",
    "* 뉴스 기사가 어느 그룹에 속하는지 분류\n",
    "* 뉴스 기사는 텍스트 데이터이기 때문에 특별한 전처리 과정이 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "AO1QR0StXwgz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _20newsgroups_dataset:\n",
      "\n",
      "The 20 newsgroups text dataset\n",
      "------------------------------\n",
      "\n",
      "The 20 newsgroups dataset comprises around 18000 newsgroups posts on\n",
      "20 topics split in two subsets: one for training (or development)\n",
      "and the other one for testing (or for performance evaluation). The split\n",
      "between the train and test set is based upon a messages posted before\n",
      "and after a specific date.\n",
      "\n",
      "This module contains two loaders. The first one,\n",
      ":func:`sklearn.datasets.fetch_20newsgroups`,\n",
      "returns a list of the raw texts that can be fed to text feature\n",
      "extractors such as :class:`~sklearn.feature_extraction.text.CountVectorizer`\n",
      "with custom parameters so as to extract feature vectors.\n",
      "The second one, :func:`sklearn.datasets.fetch_20newsgroups_vectorized`,\n",
      "returns ready-to-use features, i.e., it is not necessary to use a feature\n",
      "extractor.\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    =================   ==========\n",
      "    Classes                     20\n",
      "    Samples total            18846\n",
      "    Dimensionality               1\n",
      "    Features                  text\n",
      "    =================   ==========\n",
      "\n",
      "Usage\n",
      "~~~~~\n",
      "\n",
      "The :func:`sklearn.datasets.fetch_20newsgroups` function is a data\n",
      "fetching / caching functions that downloads the data archive from\n",
      "the original `20 newsgroups website`_, extracts the archive contents\n",
      "in the ``~/scikit_learn_data/20news_home`` folder and calls the\n",
      ":func:`sklearn.datasets.load_files` on either the training or\n",
      "testing set folder, or both of them::\n",
      "\n",
      "  >>> from sklearn.datasets import fetch_20newsgroups\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train')\n",
      "\n",
      "  >>> from pprint import pprint\n",
      "  >>> pprint(list(newsgroups_train.target_names))\n",
      "  ['alt.atheism',\n",
      "   'comp.graphics',\n",
      "   'comp.os.ms-windows.misc',\n",
      "   'comp.sys.ibm.pc.hardware',\n",
      "   'comp.sys.mac.hardware',\n",
      "   'comp.windows.x',\n",
      "   'misc.forsale',\n",
      "   'rec.autos',\n",
      "   'rec.motorcycles',\n",
      "   'rec.sport.baseball',\n",
      "   'rec.sport.hockey',\n",
      "   'sci.crypt',\n",
      "   'sci.electronics',\n",
      "   'sci.med',\n",
      "   'sci.space',\n",
      "   'soc.religion.christian',\n",
      "   'talk.politics.guns',\n",
      "   'talk.politics.mideast',\n",
      "   'talk.politics.misc',\n",
      "   'talk.religion.misc']\n",
      "\n",
      "The real data lies in the ``filenames`` and ``target`` attributes. The target\n",
      "attribute is the integer index of the category::\n",
      "\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (11314,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])\n",
      "\n",
      "It is possible to load only a sub-selection of the categories by passing the\n",
      "list of the categories to load to the\n",
      ":func:`sklearn.datasets.fetch_20newsgroups` function::\n",
      "\n",
      "  >>> cats = ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train', categories=cats)\n",
      "\n",
      "  >>> list(newsgroups_train.target_names)\n",
      "  ['alt.atheism', 'sci.space']\n",
      "  >>> newsgroups_train.filenames.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target.shape\n",
      "  (1073,)\n",
      "  >>> newsgroups_train.target[:10]\n",
      "  array([0, 1, 1, 1, 0, 1, 1, 0, 0, 0])\n",
      "\n",
      "Converting text to vectors\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "In order to feed predictive or clustering models with the text data,\n",
      "one first need to turn the text into vectors of numerical values suitable\n",
      "for statistical analysis. This can be achieved with the utilities of the\n",
      "``sklearn.feature_extraction.text`` as demonstrated in the following\n",
      "example that extract `TF-IDF`_ vectors of unigram tokens\n",
      "from a subset of 20news::\n",
      "\n",
      "  >>> from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "  >>> categories = ['alt.atheism', 'talk.religion.misc',\n",
      "  ...               'comp.graphics', 'sci.space']\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectorizer = TfidfVectorizer()\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> vectors.shape\n",
      "  (2034, 34118)\n",
      "\n",
      "The extracted TF-IDF vectors are very sparse, with an average of 159 non-zero\n",
      "components by sample in a more than 30000-dimensional space\n",
      "(less than .5% non-zero features)::\n",
      "\n",
      "  >>> vectors.nnz / float(vectors.shape[0])\n",
      "  159.01327...\n",
      "\n",
      ":func:`sklearn.datasets.fetch_20newsgroups_vectorized` is a function which \n",
      "returns ready-to-use token counts features instead of file names.\n",
      "\n",
      ".. _`20 newsgroups website`: http://people.csail.mit.edu/jrennie/20Newsgroups/\n",
      ".. _`TF-IDF`: https://en.wikipedia.org/wiki/Tf-idf\n",
      "\n",
      "\n",
      "Filtering text for more realistic training\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "\n",
      "It is easy for a classifier to overfit on particular things that appear in the\n",
      "20 Newsgroups data, such as newsgroup headers. Many classifiers achieve very\n",
      "high F-scores, but their results would not generalize to other documents that\n",
      "aren't from this window of time.\n",
      "\n",
      "For example, let's look at the results of a multinomial Naive Bayes classifier,\n",
      "which is fast to train and achieves a decent F-score::\n",
      "\n",
      "  >>> from sklearn.naive_bayes import MultinomialNB\n",
      "  >>> from sklearn import metrics\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.88213...\n",
      "\n",
      "(The example :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py` shuffles\n",
      "the training and test data, instead of segmenting by time, and in that case\n",
      "multinomial Naive Bayes gets a much higher F-score of 0.88. Are you suspicious\n",
      "yet of what's going on inside this classifier?)\n",
      "\n",
      "Let's take a look at what the most informative features are:\n",
      "\n",
      "  >>> import numpy as np\n",
      "  >>> def show_top10(classifier, vectorizer, categories):\n",
      "  ...     feature_names = np.asarray(vectorizer.get_feature_names())\n",
      "  ...     for i, category in enumerate(categories):\n",
      "  ...         top10 = np.argsort(classifier.coef_[i])[-10:]\n",
      "  ...         print(\"%s: %s\" % (category, \" \".join(feature_names[top10])))\n",
      "  ...\n",
      "  >>> show_top10(clf, vectorizer, newsgroups_train.target_names)\n",
      "  alt.atheism: edu it and in you that is of to the\n",
      "  comp.graphics: edu in graphics it is for and of to the\n",
      "  sci.space: edu it that is in and space to of the\n",
      "  talk.religion.misc: not it you in is that and to of the\n",
      "\n",
      "\n",
      "You can now see many things that these features have overfit to:\n",
      "\n",
      "- Almost every group is distinguished by whether headers such as\n",
      "  ``NNTP-Posting-Host:`` and ``Distribution:`` appear more or less often.\n",
      "- Another significant feature involves whether the sender is affiliated with\n",
      "  a university, as indicated either by their headers or their signature.\n",
      "- The word \"article\" is a significant feature, based on how often people quote\n",
      "  previous posts like this: \"In article [article ID], [name] <[e-mail address]>\n",
      "  wrote:\"\n",
      "- Other features match the names and e-mail addresses of particular people who\n",
      "  were posting at the time.\n",
      "\n",
      "With such an abundance of clues that distinguish newsgroups, the classifiers\n",
      "barely have to identify topics from text at all, and they all perform at the\n",
      "same high level.\n",
      "\n",
      "For this reason, the functions that load 20 Newsgroups data provide a\n",
      "parameter called **remove**, telling it what kinds of information to strip out\n",
      "of each file. **remove** should be a tuple containing any subset of\n",
      "``('headers', 'footers', 'quotes')``, telling it to remove headers, signature\n",
      "blocks, and quotation blocks respectively.\n",
      "\n",
      "  >>> newsgroups_test = fetch_20newsgroups(subset='test',\n",
      "  ...                                      remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                      categories=categories)\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(pred, newsgroups_test.target, average='macro')\n",
      "  0.77310...\n",
      "\n",
      "This classifier lost over a lot of its F-score, just because we removed\n",
      "metadata that has little to do with topic classification.\n",
      "It loses even more if we also strip this metadata from the training data:\n",
      "\n",
      "  >>> newsgroups_train = fetch_20newsgroups(subset='train',\n",
      "  ...                                       remove=('headers', 'footers', 'quotes'),\n",
      "  ...                                       categories=categories)\n",
      "  >>> vectors = vectorizer.fit_transform(newsgroups_train.data)\n",
      "  >>> clf = MultinomialNB(alpha=.01)\n",
      "  >>> clf.fit(vectors, newsgroups_train.target)\n",
      "  MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "\n",
      "  >>> vectors_test = vectorizer.transform(newsgroups_test.data)\n",
      "  >>> pred = clf.predict(vectors_test)\n",
      "  >>> metrics.f1_score(newsgroups_test.target, pred, average='macro')\n",
      "  0.76995...\n",
      "\n",
      "Some other classifiers cope better with this harder version of the task. Try\n",
      "running :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py` with and without\n",
      "the ``--filter`` option to compare the results.\n",
      "\n",
      ".. topic:: Recommendation\n",
      "\n",
      "  When evaluating text classifiers on the 20 Newsgroups data, you\n",
      "  should strip newsgroup-related metadata. In scikit-learn, you can do this by\n",
      "  setting ``remove=('headers', 'footers', 'quotes')``. The F-score will be\n",
      "  lower because it is more realistic.\n",
      "\n",
      ".. topic:: Examples\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_model_selection_grid_search_text_feature_extraction.py`\n",
      "\n",
      "   * :ref:`sphx_glr_auto_examples_text_plot_document_classification_20newsgroups.py`\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newsgroup = fetch_20newsgroups()\n",
    "print(newsgroup.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "3kgLZ2FRO533"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: jgreen@amber (Joe Green)\n",
      "Subject: Re: Weitek P9000 ?\n",
      "Organization: Harris Computer Systems Division\n",
      "Lines: 14\n",
      "Distribution: world\n",
      "NNTP-Posting-Host: amber.ssd.csd.harris.com\n",
      "X-Newsreader: TIN [version 1.1 PL9]\n",
      "\n",
      "Robert J.C. Kyanko (rob@rjck.UUCP) wrote:\n",
      "> abraxis@iastate.edu writes in article <abraxis.734340159@class1.iastate.edu>:\n",
      "> > Anyone know about the Weitek P9000 graphics chip?\n",
      "> As far as the low-level stuff goes, it looks pretty nice.  It's got this\n",
      "> quadrilateral fill command that requires just the four points.\n",
      "\n",
      "Do you have Weitek's address/phone number?  I'd like to get some information\n",
      "about this chip.\n",
      "\n",
      "--\n",
      "Joe Green\t\t\t\tHarris Corporation\n",
      "jgreen@csd.harris.com\t\t\tComputer Systems Division\n",
      "\"The only thing that really scares me is a person with no sense of humor.\"\n",
      "\t\t\t\t\t\t-- Jonathan Winters\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(newsgroup.data[:][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "OhrpXCEgPNyB"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroup.target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zmqchNfbXJQ"
   },
   "source": [
    "### 학습, 평가 데이터 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "MJkD4v5DX2l3"
   },
   "outputs": [],
   "source": [
    "newsgroup_train = fetch_20newsgroups(subset='train', random_state=seed)\n",
    "newsgroup_test = fetch_20newsgroups(subset='test', random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "Xxuzr5ifcLrA"
   },
   "outputs": [],
   "source": [
    "X_train, y_train = newsgroup_train.data, newsgroup_train.target\n",
    "X_test, y_test = newsgroup_test.data, newsgroup_test.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5rPb4mTPb7jA"
   },
   "source": [
    "### 벡터화\n",
    "* 텍스트 데이터는 기계학습 모델에 입력 할 수 없음\n",
    "* 벡터화는 텍스트 데이터를 실수 벡터로 변환해 기계학습 모델에 입력 할 수 있도록 하는 전처리 과정\n",
    "* Scikit-learn에서는 Count, Tf-idf, Hashing 세가지 방법을 지원"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzzFAtzkrtio"
   },
   "source": [
    "#### CountVectorizer\n",
    "* 문서에 나온 단어의 수를 count하여 벡터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "id": "U__Bmbm4r4ZN"
   },
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "l5qcYH2fr7BM"
   },
   "outputs": [],
   "source": [
    "X_train_count = count_vectorizer.fit_transform(X_train)\n",
    "X_test_count = count_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W2C7-16Zsif2"
   },
   "source": [
    "데이터를 희소 행렬(sparse matrix) 형태로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "id": "Nwmww2sOsEPV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "ie5eSVH3sH3I"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 56979)\t2\n",
      "  (0, 81727)\t1\n",
      "  (0, 65506)\t2\n",
      "  (0, 111838)\t2\n",
      "  (0, 50527)\t6\n",
      "  (0, 81794)\t1\n",
      "  (0, 63762)\t1\n",
      "  (0, 111322)\t1\n",
      "  (0, 99721)\t1\n",
      "  (0, 105252)\t3\n",
      "  (0, 28146)\t15\n",
      "  (0, 81376)\t1\n",
      "  (0, 123292)\t5\n",
      "  (0, 63828)\t1\n",
      "  (0, 116061)\t1\n",
      "  (0, 87620)\t1\n",
      "  (0, 95162)\t1\n",
      "  (0, 64095)\t1\n",
      "  (0, 51755)\t1\n",
      "  (0, 90379)\t1\n",
      "  (0, 110355)\t1\n",
      "  (0, 118983)\t1\n",
      "  (0, 89362)\t23\n",
      "  (0, 86864)\t1\n",
      "  (0, 128387)\t1\n",
      "  :\t:\n",
      "  (0, 106296)\t1\n",
      "  (0, 56500)\t1\n",
      "  (0, 119740)\t1\n",
      "  (0, 50181)\t1\n",
      "  (0, 47366)\t1\n",
      "  (0, 56899)\t1\n",
      "  (0, 27436)\t1\n",
      "  (0, 115133)\t1\n",
      "  (0, 26747)\t1\n",
      "  (0, 101358)\t1\n",
      "  (0, 99755)\t1\n",
      "  (0, 27585)\t1\n",
      "  (0, 81948)\t1\n",
      "  (0, 101000)\t1\n",
      "  (0, 99822)\t2\n",
      "  (0, 67798)\t2\n",
      "  (0, 66474)\t1\n",
      "  (0, 55223)\t1\n",
      "  (0, 83417)\t1\n",
      "  (0, 58631)\t1\n",
      "  (0, 64186)\t1\n",
      "  (0, 99872)\t1\n",
      "  (0, 117038)\t1\n",
      "  (0, 118750)\t1\n",
      "  (0, 82034)\t1\n"
     ]
    }
   ],
   "source": [
    "for v in X_train_count[0]:\n",
    "    print(v)\n",
    "# (0, 56979)    2  => 0 번째 문장에서 56979로 변환된 단어가 2개 나옴."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VuCz2fvdtLR2"
   },
   "source": [
    "#### HashingVectorizer\n",
    "* 각 단어를 해쉬 값으로 표현\n",
    "* 미리 정해진 크기의 벡터로 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "0a6w_5b4u2iU"
   },
   "outputs": [],
   "source": [
    "hash_vectorizer = HashingVectorizer(n_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "id": "Ru_bF-tuveCJ"
   },
   "outputs": [],
   "source": [
    "X_train_hash = hash_vectorizer.fit_transform(X_train)\n",
    "X_test_hash = hash_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "id": "F4FICW1kvyR2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1550687 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "xN5aaCjov0Zb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1)\t-0.017144816662454657\n",
      "  (0, 4)\t0.017144816662454657\n",
      "  (0, 5)\t-0.051434449987363975\n",
      "  (0, 10)\t0.017144816662454657\n",
      "  (0, 13)\t-0.017144816662454657\n",
      "  (0, 20)\t-0.017144816662454657\n",
      "  (0, 22)\t0.017144816662454657\n",
      "  (0, 23)\t-0.017144816662454657\n",
      "  (0, 29)\t0.051434449987363975\n",
      "  (0, 30)\t0.017144816662454657\n",
      "  (0, 32)\t0.0\n",
      "  (0, 34)\t-0.017144816662454657\n",
      "  (0, 35)\t-0.017144816662454657\n",
      "  (0, 38)\t0.051434449987363975\n",
      "  (0, 39)\t-0.017144816662454657\n",
      "  (0, 40)\t-0.08572408331227328\n",
      "  (0, 47)\t0.017144816662454657\n",
      "  (0, 56)\t0.034289633324909315\n",
      "  (0, 60)\t-0.017144816662454657\n",
      "  (0, 61)\t-0.017144816662454657\n",
      "  (0, 62)\t0.017144816662454657\n",
      "  (0, 64)\t-0.017144816662454657\n",
      "  (0, 66)\t-0.017144816662454657\n",
      "  (0, 69)\t-0.017144816662454657\n",
      "  (0, 70)\t0.034289633324909315\n",
      "  :\t:\n",
      "  (0, 933)\t-0.017144816662454657\n",
      "  (0, 935)\t0.017144816662454657\n",
      "  (0, 937)\t-0.06857926664981863\n",
      "  (0, 939)\t-0.034289633324909315\n",
      "  (0, 940)\t-0.017144816662454657\n",
      "  (0, 942)\t-0.017144816662454657\n",
      "  (0, 945)\t-0.034289633324909315\n",
      "  (0, 946)\t0.0\n",
      "  (0, 949)\t0.017144816662454657\n",
      "  (0, 950)\t0.017144816662454657\n",
      "  (0, 953)\t0.0\n",
      "  (0, 956)\t0.017144816662454657\n",
      "  (0, 958)\t-0.5143444998736397\n",
      "  (0, 960)\t0.017144816662454657\n",
      "  (0, 967)\t0.034289633324909315\n",
      "  (0, 969)\t-0.017144816662454657\n",
      "  (0, 972)\t-0.017144816662454657\n",
      "  (0, 973)\t-0.017144816662454657\n",
      "  (0, 975)\t-0.017144816662454657\n",
      "  (0, 980)\t-0.017144816662454657\n",
      "  (0, 982)\t-0.017144816662454657\n",
      "  (0, 987)\t-0.034289633324909315\n",
      "  (0, 988)\t0.034289633324909315\n",
      "  (0, 991)\t0.017144816662454657\n",
      "  (0, 996)\t0.06857926664981863\n"
     ]
    }
   ],
   "source": [
    "print(X_train_hash[0])\n",
    "# (0, 1)     -0.017144816662454657  => 1번에 해당되는 단어가 -0.017144816662454657 로 지정됨"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jo_5elqewPmi"
   },
   "source": [
    "#### TfidfVectorizer\n",
    "* 문서에 나온 단어 빈도(term frequency)와 역문서 빈도(inverse document frequency)를 곱해서 구함\n",
    "* 각 빈도는 일반적으로 로그 스케일링 후 사용\n",
    "* $tf(t, d) = log(f(t, d) + 1)$\n",
    "* $idf(t, D) = \\frac{|D|}{|d \\in D : t \\in d| + 1}$\n",
    "* $tfidf(t, d, D) = tf(t, d) \\times idf(t, D)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "se6YLbOBb9yd"
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "id": "BCB_vPEUcqSi"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x130107 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1787565 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "id": "31lIqMzz0b4C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 82034)\t0.02906545716508147\n",
      "  (0, 118750)\t0.052057796632427544\n",
      "  (0, 117038)\t0.03477688699499205\n",
      "  (0, 99872)\t0.048967744908037666\n",
      "  (0, 64186)\t0.016096202546335266\n",
      "  (0, 58631)\t0.05097971092791811\n",
      "  (0, 83417)\t0.048722326267761205\n",
      "  (0, 55223)\t0.04080184883099661\n",
      "  (0, 66474)\t0.04647326250518383\n",
      "  (0, 67798)\t0.059792913274850645\n",
      "  (0, 99822)\t0.04137484330967798\n",
      "  (0, 101000)\t0.05616860821913193\n",
      "  (0, 81948)\t0.03427033345369121\n",
      "  (0, 27585)\t0.04189289786375994\n",
      "  (0, 99755)\t0.02291131215153194\n",
      "  (0, 101358)\t0.03188666925379369\n",
      "  (0, 26747)\t0.028016451392658633\n",
      "  (0, 115133)\t0.017792119267022198\n",
      "  (0, 27436)\t0.013544037372383787\n",
      "  (0, 56899)\t0.05974117632649521\n",
      "  (0, 47366)\t0.049486034840061595\n",
      "  (0, 50181)\t0.03791452763719546\n",
      "  (0, 119740)\t0.020661195198140053\n",
      "  (0, 56500)\t0.04564952168797066\n",
      "  (0, 106296)\t0.03933512350323768\n",
      "  :\t:\n",
      "  (0, 128387)\t0.030896006107493282\n",
      "  (0, 86864)\t0.018421736387380972\n",
      "  (0, 89362)\t0.18252364213369413\n",
      "  (0, 118983)\t0.013539308162066799\n",
      "  (0, 110355)\t0.02203560294619601\n",
      "  (0, 90379)\t0.00727560631954796\n",
      "  (0, 51755)\t0.05974117632649521\n",
      "  (0, 64095)\t0.0129314321558398\n",
      "  (0, 95162)\t0.012584775069828991\n",
      "  (0, 87620)\t0.01302304464289338\n",
      "  (0, 116061)\t0.038448658376876395\n",
      "  (0, 63828)\t0.04721012377545349\n",
      "  (0, 123292)\t0.06632898853563748\n",
      "  (0, 81376)\t0.04505395236643462\n",
      "  (0, 28146)\t0.12429033671126889\n",
      "  (0, 105252)\t0.07363354198189741\n",
      "  (0, 99721)\t0.009598104236445673\n",
      "  (0, 111322)\t0.006993713590608497\n",
      "  (0, 63762)\t0.05489350346952116\n",
      "  (0, 81794)\t0.02810442379273205\n",
      "  (0, 50527)\t0.05981557141340942\n",
      "  (0, 111838)\t0.10009166122509422\n",
      "  (0, 65506)\t0.08492053337811943\n",
      "  (0, 81727)\t0.055502036119311086\n",
      "  (0, 56979)\t0.013987427181216995\n"
     ]
    }
   ],
   "source": [
    "for v in X_train_tfidf[0]:\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fgodSTr0gEd"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dw1V6JPISYNj"
   },
   "source": [
    "## 가우시안 나이브 베이즈\n",
    "\n",
    "* 입력 특성이 가우시안(정규) 분포를 갖는다고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HxluuRDrfEE-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RHlxf5Uvur1s"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PRkCzNTavChE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c7LlOoOU4oos"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQmypOJ07flk"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5cVrpkP43Uq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uWAIT1YZ5IPK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yyh8EaLW8BcK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rOYltZx7mdM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63VKVU7xVKh0"
   },
   "source": [
    "## 베르누이 나이브 베이즈\n",
    "\n",
    "* 입력 특성이 베르누이 분포에 의해 생성된 이진 값을 갖는 다고 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ukxegxdakI06"
   },
   "source": [
    "### 학습 및 평가 (Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MY1gkbgZWPSy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cFFYkHXkgLgC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtT6NPFAjfto"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0TZnffru9JVK"
   },
   "source": [
    "### 학습 및 평가 (Hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j_mVW1So9M0c"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8b4dNF39SC6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vpjYy1Pi9dxc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTP0dYKlkOLR"
   },
   "source": [
    "### 학습 및 평가 (Tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7TElQGCjMMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q5XRlZVujO_x"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rSFVn5ggjqgg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rCwhaAT1924_"
   },
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5yzCFaKy9-5u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Szx9XA-O9_qF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQFM2BEU-Cv2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fEpjHMVf-HfD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zEyFa-B5XGrP"
   },
   "source": [
    "## 다항 나이브 베이즈\n",
    "\n",
    "* 입력 특성이 다항분포에 의해 생성된 빈도수 값을 갖는 다고 가정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "75lWu6PQlXpi"
   },
   "source": [
    "### 학습 및 평가 (Count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRlaJMtNNLMC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TLS0R7q6UPt7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L_WeeHT0lRil"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S77kYdhjly0t"
   },
   "source": [
    "### 학습 및 평가 (Tf-idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CnFaY_MSlVMb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jTi-ABxl32n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dUVdI3VDl51E"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1b9hGlLAu49"
   },
   "source": [
    "### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m11zMDG7mL4m"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OnhxioK8A6oP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2B7YDSg4A9EB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UbMChTaxBAyk"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "_7 나이브 베이즈 분류(Naive Bayes Classification).ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
